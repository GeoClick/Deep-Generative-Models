{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from math import log, pi, exp\n",
    "import numpy as np\n",
    "from scipy import linalg as la\n",
    "\n",
    "logabs = lambda x: torch.log(torch.abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActNorm(nn.Module):\n",
    "    def __init__(self, in_channel, logdet=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.loc = nn.Parameter(torch.zeros(1, in_channel, 1, 1))\n",
    "        self.scale = nn.Parameter(torch.ones(1, in_channel, 1, 1))\n",
    "\n",
    "        self.initialized = False\n",
    "        self.logdet = logdet\n",
    "\n",
    "    def initialize(self, input):\n",
    "        with torch.no_grad():\n",
    "            flatten = input.permute(1, 0, 2, 3).contiguous().view(input.shape[1], -1)\n",
    "            mean = (\n",
    "                flatten.mean(1)\n",
    "                .unsqueeze(1)\n",
    "                .unsqueeze(2)\n",
    "                .unsqueeze(3)\n",
    "                .permute(1, 0, 2, 3)\n",
    "            )\n",
    "            std = (\n",
    "                flatten.std(1)\n",
    "                .unsqueeze(1)\n",
    "                .unsqueeze(2)\n",
    "                .unsqueeze(3)\n",
    "                .permute(1, 0, 2, 3)\n",
    "            )\n",
    "\n",
    "            self.loc.data.copy_(-mean)\n",
    "            self.scale.data.copy_(1 / (std + 1e-6))\n",
    "\n",
    "    def forward(self, input):\n",
    "        _, _, height, width = input.shape\n",
    "\n",
    "        if not self.initialized:\n",
    "            self.initialize(input)\n",
    "            self.initialized = True\n",
    "\n",
    "        log_abs = logabs(self.scale)\n",
    "\n",
    "        logdet = height * width * torch.sum(log_abs)\n",
    "\n",
    "        if self.logdet:\n",
    "            return self.scale * (input + self.loc), logdet\n",
    "\n",
    "        else:\n",
    "            return self.scale * (input + self.loc)\n",
    "\n",
    "    def reverse(self, output):\n",
    "        return output / self.scale - self.loc\n",
    "\n",
    "\n",
    "class InvConv2d(nn.Module):\n",
    "    def __init__(self, in_channel):\n",
    "        super().__init__()\n",
    "\n",
    "        weight = torch.randn(in_channel, in_channel)\n",
    "        q, _ = torch.qr(weight)\n",
    "        weight = q.unsqueeze(2).unsqueeze(3)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "\n",
    "    def forward(self, input):\n",
    "        _, _, height, width = input.shape\n",
    "\n",
    "        out = F.conv2d(input, self.weight)\n",
    "        logdet = (\n",
    "            height * width * torch.slogdet(self.weight.squeeze().double())[1].float()\n",
    "        )\n",
    "\n",
    "        return out, logdet\n",
    "\n",
    "    def reverse(self, output):\n",
    "        return F.conv2d(\n",
    "            output, self.weight.squeeze().inverse().unsqueeze(2).unsqueeze(3)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvConv2dLU(nn.Module):\n",
    "    def __init__(self, in_channel):\n",
    "        super().__init__()\n",
    "\n",
    "        weight = np.random.randn(in_channel, in_channel)\n",
    "        q, _ = la.qr(weight)\n",
    "        w_p, w_l, w_u = la.lu(q.astype(np.float32))\n",
    "        w_s = np.diag(w_u)\n",
    "        w_u = np.triu(w_u, 1)\n",
    "        u_mask = np.triu(np.ones_like(w_u), 1)\n",
    "        l_mask = u_mask.T\n",
    "\n",
    "        w_p = torch.from_numpy(w_p)\n",
    "        w_l = torch.from_numpy(w_l)\n",
    "        w_s = torch.from_numpy(w_s)\n",
    "        w_u = torch.from_numpy(w_u)\n",
    "\n",
    "        self.register_buffer('w_p', w_p)\n",
    "        self.register_buffer('u_mask', torch.from_numpy(u_mask))\n",
    "        self.register_buffer('l_mask', torch.from_numpy(l_mask))\n",
    "        self.register_buffer('s_sign', torch.sign(w_s))\n",
    "        self.register_buffer('l_eye', torch.eye(l_mask.shape[0]))\n",
    "        self.w_l = nn.Parameter(w_l)\n",
    "        self.w_s = nn.Parameter(logabs(w_s))\n",
    "        self.w_u = nn.Parameter(w_u)\n",
    "\n",
    "    def forward(self, input):\n",
    "        _, _, height, width = input.shape\n",
    "\n",
    "        weight = self.calc_weight()\n",
    "\n",
    "        out = F.conv2d(input, weight)\n",
    "        logdet = height * width * sum(self.w_s)\n",
    "\n",
    "        return out, logdet\n",
    "\n",
    "    def calc_weight(self):\n",
    "        weight = (\n",
    "            self.w_p\n",
    "            @ (self.w_l * self.l_mask + self.l_eye)\n",
    "            @ ((self.w_u * self.u_mask) + torch.diag(self.s_sign * torch.exp(self.w_s)))\n",
    "        )\n",
    "\n",
    "        return weight.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "    def reverse(self, output):\n",
    "        weight = self.calc_weight()\n",
    "\n",
    "        return F.conv2d(output, weight.squeeze().inverse().unsqueeze(2).unsqueeze(3))\n",
    "\n",
    "\n",
    "class ZeroConv2d(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, padding=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, 3, padding=0)\n",
    "        self.conv.weight.data.zero_()\n",
    "        self.conv.bias.data.zero_()\n",
    "        self.scale = nn.Parameter(torch.zeros(1, out_channel, 1, 1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = F.pad(input, [1, 1, 1, 1], value=1)\n",
    "        out = self.conv(out)\n",
    "        out = out * torch.exp(self.scale * 3)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineCoupling(nn.Module):\n",
    "    def __init__(self, in_channel, filter_size=512, affine=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.affine = affine\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channel // 2, filter_size, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(filter_size, filter_size, 1),\n",
    "            nn.ReLU(),\n",
    "            ZeroConv2d(filter_size, in_channel if self.affine else in_channel // 2),\n",
    "        )\n",
    "\n",
    "        self.net[0].weight.data.normal_(0, 0.05)\n",
    "        self.net[0].bias.data.zero_()\n",
    "\n",
    "        self.net[2].weight.data.normal_(0, 0.05)\n",
    "        self.net[2].bias.data.zero_()\n",
    "\n",
    "    def forward(self, input):\n",
    "        in_a, in_b = input.chunk(2, 1)\n",
    "\n",
    "        if self.affine:\n",
    "            log_s, t = self.net(in_a).chunk(2, 1)\n",
    "            # s = torch.exp(log_s)\n",
    "            s = F.sigmoid(log_s + 2)\n",
    "            # out_a = s * in_a + t\n",
    "            out_b = (in_b + t) * s\n",
    "\n",
    "            logdet = torch.sum(torch.log(s).view(input.shape[0], -1), 1)\n",
    "\n",
    "        else:\n",
    "            net_out = self.net(in_a)\n",
    "            out_b = in_b + net_out\n",
    "            logdet = None\n",
    "\n",
    "        return torch.cat([in_a, out_b], 1), logdet\n",
    "\n",
    "    def reverse(self, output):\n",
    "        out_a, out_b = output.chunk(2, 1)\n",
    "\n",
    "        if self.affine:\n",
    "            log_s, t = self.net(out_a).chunk(2, 1)\n",
    "            # s = torch.exp(log_s)\n",
    "            s = F.sigmoid(log_s + 2)\n",
    "            # in_a = (out_a - t) / s\n",
    "            in_b = out_b / s - t\n",
    "\n",
    "        else:\n",
    "            net_out = self.net(out_a)\n",
    "            in_b = out_b - net_out\n",
    "\n",
    "        return torch.cat([out_a, in_b], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flow(nn.Module):\n",
    "    def __init__(self, in_channel, affine=True, conv_lu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.actnorm = ActNorm(in_channel)\n",
    "\n",
    "        if conv_lu:\n",
    "            self.invconv = InvConv2dLU(in_channel)\n",
    "\n",
    "        else:\n",
    "            self.invconv = InvConv2d(in_channel)\n",
    "\n",
    "        self.coupling = AffineCoupling(in_channel, affine=affine)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out, logdet = self.actnorm(input)\n",
    "        out, det1 = self.invconv(out)\n",
    "        out, det2 = self.coupling(out)\n",
    "\n",
    "        logdet = logdet + det1\n",
    "        if det2 is not None:\n",
    "            logdet = logdet + det2\n",
    "\n",
    "        return out, logdet\n",
    "\n",
    "    def reverse(self, output):\n",
    "        input = self.coupling.reverse(output)\n",
    "        input = self.invconv.reverse(input)\n",
    "        input = self.actnorm.reverse(input)\n",
    "\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_log_p(x, mean, log_sd):\n",
    "    return -0.5 * log(2 * pi) - log_sd - 0.5 * (x - mean) ** 2 / torch.exp(2 * log_sd)\n",
    "\n",
    "\n",
    "def gaussian_sample(eps, mean, log_sd):\n",
    "    return mean + torch.exp(log_sd) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channel, n_flow, split=True, affine=True, conv_lu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        squeeze_dim = in_channel * 4\n",
    "\n",
    "        self.flows = nn.ModuleList()\n",
    "        for i in range(n_flow):\n",
    "            self.flows.append(Flow(squeeze_dim, affine=affine, conv_lu=conv_lu))\n",
    "\n",
    "        self.split = split\n",
    "\n",
    "        if split:\n",
    "            self.prior = ZeroConv2d(in_channel * 2, in_channel * 4)\n",
    "\n",
    "        else:\n",
    "            self.prior = ZeroConv2d(in_channel * 4, in_channel * 8)\n",
    "\n",
    "    def forward(self, input):\n",
    "        b_size, n_channel, height, width = input.shape\n",
    "        squeezed = input.view(b_size, n_channel, height // 2, 2, width // 2, 2)\n",
    "        squeezed = squeezed.permute(0, 1, 3, 5, 2, 4)\n",
    "        out = squeezed.contiguous().view(b_size, n_channel * 4, height // 2, width // 2)\n",
    "\n",
    "        logdet = 0\n",
    "\n",
    "        for flow in self.flows:\n",
    "            out, det = flow(out)\n",
    "            logdet = logdet + det\n",
    "\n",
    "        if self.split:\n",
    "            out, z_new = out.chunk(2, 1)\n",
    "            mean, log_sd = self.prior(out).chunk(2, 1)\n",
    "            log_p = gaussian_log_p(z_new, mean, log_sd)\n",
    "            log_p = log_p.view(b_size, -1).sum(1)\n",
    "\n",
    "        else:\n",
    "            zero = torch.zeros_like(out)\n",
    "            mean, log_sd = self.prior(zero).chunk(2, 1)\n",
    "            log_p = gaussian_log_p(out, mean, log_sd)\n",
    "            log_p = log_p.view(b_size, -1).sum(1)\n",
    "            z_new = out\n",
    "\n",
    "        return out, logdet, log_p\n",
    "\n",
    "    def reverse(self, output, eps=None):\n",
    "        input = output\n",
    "\n",
    "        if self.split:\n",
    "            mean, log_sd = self.prior(input).chunk(2, 1)\n",
    "            z = gaussian_sample(eps, mean, log_sd)\n",
    "            input = torch.cat([output, z], 1)\n",
    "\n",
    "        else:\n",
    "            zero = torch.zeros_like(input)\n",
    "            # zero = F.pad(zero, [1, 1, 1, 1], value=1)\n",
    "            mean, log_sd = self.prior(zero).chunk(2, 1)\n",
    "            z = gaussian_sample(eps, mean, log_sd)\n",
    "            input = z\n",
    "\n",
    "        for flow in self.flows[::-1]:\n",
    "            input = flow.reverse(input)\n",
    "\n",
    "        b_size, n_channel, height, width = input.shape\n",
    "\n",
    "        unsqueezed = input.view(b_size, n_channel // 4, 2, 2, height, width)\n",
    "        unsqueezed = unsqueezed.permute(0, 1, 4, 2, 5, 3)\n",
    "        unsqueezed = unsqueezed.contiguous().view(\n",
    "            b_size, n_channel // 4, height * 2, width * 2\n",
    "        )\n",
    "\n",
    "        return unsqueezed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Glow(nn.Module):\n",
    "    def __init__(self, in_channel, n_flow, n_block, affine=True, conv_lu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        n_channel = in_channel\n",
    "        for i in range(n_block - 1):\n",
    "            self.blocks.append(Block(n_channel, n_flow, affine=affine, conv_lu=conv_lu))\n",
    "            n_channel *= 2\n",
    "        self.blocks.append(Block(n_channel, n_flow, split=False, affine=affine))\n",
    "\n",
    "    def forward(self, input):\n",
    "        log_p_sum = 0\n",
    "        logdet = 0\n",
    "        out = input\n",
    "\n",
    "        for block in self.blocks:\n",
    "            out, det, log_p = block(out)\n",
    "            logdet = logdet + det\n",
    "\n",
    "            if log_p is not None:\n",
    "                log_p_sum = log_p_sum + log_p\n",
    "\n",
    "        return log_p_sum, logdet\n",
    "\n",
    "    def reverse(self, z_list):\n",
    "        for i, block in enumerate(self.blocks[::-1]):\n",
    "            if i == 0:\n",
    "                input = block.reverse(z_list[-1], z_list[-1])\n",
    "\n",
    "            else:\n",
    "                input = block.reverse(input, z_list[-(i + 1)])\n",
    "\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from math import log, sqrt, pi\n",
    "\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "from model import Glow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=[], dest='path', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Path to image directory', metavar='PATH')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Glow trainer')\n",
    "parser.add_argument('--batch', default=16, type=int, help='batch size')\n",
    "parser.add_argument('--iter', default=200000, type=int, help='maximum iterations')\n",
    "parser.add_argument(\n",
    "    '--n_flow', default=32, type=int, help='number of flows in each block'\n",
    ")\n",
    "parser.add_argument('--n_block', default=4, type=int, help='number of blocks')\n",
    "parser.add_argument(\n",
    "    '--no_lu',\n",
    "    action='store_true',\n",
    "    help='use plain convolution instead of LU decomposed version',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--affine', action='store_true', help='use affine coupling instead of additive'\n",
    ")\n",
    "parser.add_argument('--n_bits', default=5, type=int, help='number of bits')\n",
    "parser.add_argument('--lr', default=1e-4, type=float, help='learning rate')\n",
    "parser.add_argument('--img_size', default=64, type=int, help='image size')\n",
    "parser.add_argument('--temp', default=0.7, type=float, help='temperature of sampling')\n",
    "parser.add_argument('--n_sample', default=20, type=int, help='number of samples')\n",
    "parser.add_argument('path', metavar='PATH', type=str, help='Path to image directory')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(path, batch_size, image_size):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (1, 1, 1)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = datasets.ImageFolder(path, transform=transform)\n",
    "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=4)\n",
    "    loader = iter(loader)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            yield next(loader)\n",
    "\n",
    "        except StopIteration:\n",
    "            loader = DataLoader(\n",
    "                dataset, shuffle=True, batch_size=batch_size, num_workers=4\n",
    "            )\n",
    "            loader = iter(loader)\n",
    "            yield next(loader)\n",
    "\n",
    "\n",
    "def calc_z_shapes(n_channel, input_size, n_flow, n_block):\n",
    "    z_shapes = []\n",
    "\n",
    "    for i in range(n_block - 1):\n",
    "        input_size //= 2\n",
    "        n_channel *= 2\n",
    "\n",
    "        z_shapes.append((n_channel, input_size, input_size))\n",
    "\n",
    "    input_size //= 2\n",
    "    z_shapes.append((n_channel * 4, input_size, input_size))\n",
    "\n",
    "    return z_shapes\n",
    "\n",
    "\n",
    "def calc_loss(log_p, logdet, image_size, n_bins):\n",
    "    # log_p = calc_log_p([z_list])\n",
    "    n_pixel = image_size * image_size * 3\n",
    "\n",
    "    loss = -log(n_bins) * n_pixel\n",
    "    loss = loss + logdet + log_p\n",
    "\n",
    "    return (\n",
    "        (-loss / (log(2) * n_pixel)).mean(),\n",
    "        (log_p / (log(2) * n_pixel)).mean(),\n",
    "        (logdet / (log(2) * n_pixel)).mean(),\n",
    "    )\n",
    "\n",
    "\n",
    "def train(args, model, optimizer):\n",
    "    dataset = iter(sample_data(args.path, args.batch, args.img_size))\n",
    "    n_bins = 2. ** args.n_bits\n",
    "\n",
    "    z_sample = []\n",
    "    z_shapes = calc_z_shapes(3, args.img_size, args.n_flow, args.n_block)\n",
    "    for z in z_shapes:\n",
    "        z_new = torch.randn(args.n_sample, *z) * args.temp\n",
    "        z_sample.append(z_new.to(device))\n",
    "\n",
    "    with tqdm(range(args.iter)) as pbar:\n",
    "        for i in pbar:\n",
    "            image, _ = next(dataset)\n",
    "            image = image.to(device)\n",
    "\n",
    "            if i == 0:\n",
    "                log_p, logdet = model.module(image + torch.rand_like(image) / n_bins)\n",
    "\n",
    "            else:\n",
    "                log_p, logdet = model(image + torch.rand_like(image) / n_bins)\n",
    "\n",
    "            loss, log_p, log_det = calc_loss(log_p, logdet, args.img_size, n_bins)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            # warmup_lr = args.lr * min(1, i * batch_size / (50000 * 10))\n",
    "            warmup_lr = args.lr\n",
    "            optimizer.param_groups[0]['lr'] = warmup_lr\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_description(\n",
    "                f'Loss: {loss.item():.5f}; logP: {log_p.item():.5f}; logdet: {log_det.item():.5f}; lr: {warmup_lr:.7f}'\n",
    "            )\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                with torch.no_grad():\n",
    "                    utils.save_image(\n",
    "                        model_single.reverse(z_sample).cpu().data,\n",
    "                        f'sample/{str(i + 1).zfill(6)}.png',\n",
    "                        normalize=True,\n",
    "                        nrow=10,\n",
    "                        range=(-0.5, 0.5),\n",
    "                    )\n",
    "\n",
    "            if i % 10000 == 0:\n",
    "                torch.save(\n",
    "                    model.state_dict(), f'checkpoint/model_{str(i + 1).zfill(6)}.pt'\n",
    "                )\n",
    "                torch.save(\n",
    "                    optimizer.state_dict(), f'checkpoint/optim_{str(i + 1).zfill(6)}.pt'\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArgumentParser(prog='ipykernel_launcher.py', usage=None, description='Glow trainer', formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\admin\\\\Desktop\\\\glow-pytorch-master'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = QApplication(sys.argv)\n",
    "app.aboutToQuit.connect(app.deleteLater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch BATCH] [--iter ITER]\n",
      "                             [--n_flow N_FLOW] [--n_block N_BLOCK] [--no_lu]\n",
      "                             [--affine] [--n_bits N_BITS] [--lr LR]\n",
      "                             [--img_size IMG_SIZE] [--temp TEMP]\n",
      "                             [--n_sample N_SAMPLE]\n",
      "                             PATH\n",
      "ipykernel_launcher.py: error: unrecognized arguments: C:\\Users\\admin\\AppData\\Roaming\\jupyter\\runtime\\kernel-e2c65299-ffdb-4814-8f94-9c43b911e330.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    sys.argv[1] = \"PATH\"\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "\n",
    "    model_single = Glow(\n",
    "        3, args.n_flow, args.n_block, affine=args.affine, conv_lu=not args.no_lu\n",
    "    )\n",
    "    model = nn.DataParallel(model_single)\n",
    "    # model = model_single\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    train(args, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--sum] N [N ...]\n",
      "ipykernel_launcher.py: error: argument N: invalid int value: 'PATH'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "sys.argv[1] = \"PATH\"\n",
    "parser = argparse.ArgumentParser(description='Process some integers.')\n",
    "parser.add_argument('integers', metavar='N', type=int, nargs='+',\n",
    "                    help='an integer for the accumulator')\n",
    "parser.add_argument('--sum', dest='accumulate', action='store_const',\n",
    "                    const=sum, default=max,\n",
    "                    help='sum the integers (default: find the max)')\n",
    "\n",
    "args = parser.parse_args()\n",
    "print(args.accumulate(args.integers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch ",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
